# Why this "tuned" version ?

While investigating the performances difference of Fortran and C++
(especially the `C++-NoCopy` version) on the Weno test, it arises that
the C++ binaries lack of vectorization.
More precisely, the tested Fortran compilers are able to mainly use AVX 256bits
instructions for the Weno reconstruction kernel while the C++ compilers
were almost always limited to AVX 128bits.

## The Weno kernel benchmark
The file `bench_WenoLeftRightRecKernel_O3.cpp' contains some experiments
on the compiler's skills (in `-03` optimization mode) to generate fast binary
of the `WenoLeftRightRecKernel` function of `Weno.hpp` depending on the way
its result is manipulated.

It seems that the operations applied to the kernel results affect the compiler
ability to generate fast binary of the same kernel with performance penalty
up to a factor 3.
Even equivalent ways of doing the same operations affect the performances.

### How to run this micro benchmark
This benchmark can be compiled with
```bash
$C++ -std=c++14 -03 -march=native -mtune=native -DNDEBUG -DTEST=N bench_WenoLeftRightRecKernel_O3.cpp bench_checksup.cpp -o bench
```
where `N` is a integer between 1 and 23 that specifies which operations
should be applied to the Weno kernel results
(see `bench_WenoLeftRightRecKernel_O3.cpp`).

The binary can be run with
```bash
numactl -C0 -m0 ./bench SIZE NRUN FREQ
```
where SIZE is the size of the discretized space on which the kernel is applied
(typically 10000000), NRUN is the number of consecutive runs (5) and FREQ
is your processor frequency (2200) in order to accuratly calculate the number
of cycles per execution of the kernel.

In order to have accurate timings, you should disable some energy saving
features like TurboBoost (see https://askubuntu.com/a/619881).

The `bench_WenoLeftRightRecKernel.sh` script uses an environment module system
(e.g. lmod) to automatically bench the 23 tests on a given set of compilers.

The `bench_to_table.py` Python script allows to filter and convert the results
into an HTML or Markdown table.


### Global results
The following table contains the measured cycles per execution (lower is better)
of the kernel together with the calculations applied to its results,
on an Intel Xeon E5-2650 v4 @ 2.20GHz:

|  | **GNU** | | | | | **Clang** | | | **Intel** | |
|-|-|-|-|-|-|-|-|-|-|-|
|  | **4.9.4** | **5.5.0** | **6.4.0** | **7.3.0** | **8.1.0** | **3.8.0** | **5.0.0** | **6.0.0** | **17.0.2** | **18.0.3** |
| **1** | 58.0 | 57.8 | 56.5 | 57.5 | 32.5 | 66.5 | 59.6 | 56.6 | 32.4 | 32.5 |
| **2** | 61.4 | 61.3 | 59.7 | 80.3 | 32.6 | 66.7 | 63.6 | 61.1 | 32.4 | 32.4 |
| **3** | 75.5 | 76.4 | 74.6 | 74.8 | 74.3 | 68.3 | 64.4 | 61.4 | 32.4 | 32.4 |
| **4** | 59.4 | 58.6 | 58.5 | 75.9 | 32.5 | 66.6 | 61.2 | 58.8 | 32.4 | 32.5 |
| **5** | 75.5 | 75.6 | 74.8 | 75.7 | 77.5 | 66.3 | 62.7 | 59.9 | 32.4 | 32.4 |
| **6** | 75.5 | 75.6 | 74.8 | 75.7 | 77.5 | 66.3 | 62.7 | 59.9 | 32.4 | 32.5 |
| **7** | 56.6 | 57.7 | 56.8 | 75.5 | 32.5 | 65.3 | 62.2 | 58.5 | 32.4 | 32.4 |
| **8** | 58.6 | 59.3 | 59.2 | 78.0 | 32.6 | 67.0 | 61.4 | 58.6 | 32.4 | 32.4 |
| **9** | 57.9 | 58.8 | 57.4 | 81.6 | 32.5 | 66.7 | 62.6 | 59.6 | 32.4 | 32.5 |
| **10** | 80.7 | 80.0 | 77.3 | 78.6 | 78.2 | 82.6 | 80.1 | 78.3 | 32.6 | 32.5 |
| **11** | 81.5 | 80.5 | 79.7 | 81.4 | 80.3 | 86.1 | 83.6 | 79.4 | 33.0 | 79.0 |
| **12** | 59.1 | 59.3 | 59.2 | 59.5 | 58.2 | 64.7 | 60.9 | 57.0 | 57.8 | 57.6 |
| **13** | 76.7 | 76.9 | 76.5 | 77.1 | 76.1 | 82.2 | 79.8 | 77.4 | 32.4 | 32.5 |
| **14** | 62.8 | 64.0 | 63.2 | 81.2 | 82.8 | 69.1 | 66.7 | 64.3 | 87.4 | 80.0 |
| **15** | 86.8 | 82.2 | 79.6 | 80.6 | 33.4 | 69.8 | 67.9 | 64.3 | 32.4 | 32.4 |
| **16** | 75.4 | 76.5 | 74.5 | 75.2 | 74.4 | 68.3 | 64.1 | 61.8 | 32.4 | 32.4 |
| **17** | 66.7 | 65.1 | 64.4 | 79.1 | 32.6 | 71.4 | 68.1 | 63.6 | 32.5 | 32.5 |
| **18** | 63.6 | 63.7 | 63.0 | 77.3 | 32.6 | 68.1 | 66.3 | 62.8 | 32.4 | 32.4 |
| **19** | 67.6 | 66.6 | 66.6 | 80.7 | 32.6 | 76.1 | 70.4 | 66.8 | 32.5 | 32.6 |
| **20** | 69.5 | 68.3 | 67.6 | 81.7 | 82.2 | 77.7 | 73.5 | 68.9 | 79.1 | 78.6 |
| **21** | 81.3 | 69.6 | 68.8 | 36.3 | 36.7 | 92.4 | 89.4 | 71.9 | 83.4 | 34.8 |
| **22** | 80.3 | 80.3 | 79.1 | 80.3 | 79.8 | 83.8 | 82.4 | 78.8 | 78.2 | 78.1 |
| **23** | 87.9 | 69.4 | 68.9 | 36.3 | 36.7 | 92.4 | 83.8 | 71.9 | 82.5 | 34.8 |
(generated by `./bench_to_table.py bench.dat Markdown`)

Some of the tests will be described in the next section.
The test with id 22 is comparable to the full Weno bench of the `C++-NoCopy`
version while the 23th test is for the current "tuned" version.

Note that the calculations applied to the kernel's results are generally light
and implie a penalty of a few cycles.


### GNU/8 and Intel/18 results analysis
In the previous table, the compilers that generate the fastest binaries
are GNU/8.1.0 and Intel/18.0.3.
In this section, we describe some of the tests and the corresponding results
of these two compilers.

#### Tests 1, 4 and 5

Test 1:
```C++
checksum += result.first + result.second;
```

Test 4:
```C++
checksum += result.first <= result.second ? result.first : result.second;
```

Test 5:
```C++
checksum += result.first <= result.second ? 0.5 * result.first : 0.5 * result.second;
```

|  | **GNU/8.1.0** | **Intel/18.0.3** |
|-|-|-|
| **1** | 32.5 | 32.5 |
| **4** | 32.5 | 32.5 |
| **5** | 77.5 | 32.4 |
(generated by `./bench_to_table.py bench.dat Markdown -C -f 'GNU/8|Intel/18' -t '1,4,5'`)

The test 1 is a very simple calculation done on the two Weno reconstructions
and the two compilers performs well on it.
The test 4 and 5 differ only on the `0.5` factor but the GNU compiler's
performance is divided by more than two between this two tests.

#### Tests 9, 10 and 11

Test 9:
```C++
checksum += 0.5 * std::pow( std::min(result.first, result.second), 2);
```

Test 10:
```C++
checksum += result.first <= result.second
    ? ( result.second <= 0
        ? 0.5 * result.second * result.second
        : ( result.first >= 0 ? 0.5 * result.first * result.first : 0 ) )
    : std::max( 0.5 * result.first * result.first, 0.5 * result.second * result.second );
```

Test 11:
```C++
checksum += 0.5 * std::pow( std::min(result.first, result.second), 2);
checksum += result.first <= result.second
    ? ( result.second <= 0
        ? 0.5 * result.second * result.second
        : ( result.first >= 0 ? 0.5 * result.first * result.first : 0 ) )
    : std::max( 0.5 * result.first * result.first, 0.5 * result.second * result.second );
```

|  | **GNU/8.1.0** | **Intel/18.0.3** |
|-|-|-|
| **9** | 32.5 | 32.5 |
| **10** | 78.2 | 32.5 |
| **11** | 80.3 | 79.0 |
(generated by `./bench_to_table.py bench.dat Markdown -C -f 'GNU/8|Intel/18' -t '9-11'`)

The 11th test is just a concatenation of tests 9 and 10 but the Intel compiler
fails to generate the same good binary.

#### Tests 14 and 15

Test 14:
```C++
checksum += std::min(
    std::min( 0.5 * result.first * result.first, 0.5 * result.second * result.second ),
    std::max( 0.5 * result.first * result.first, 0.5 * result.second * result.second )
);
```

Test 15:
```C++
const auto a = std::min( 0.5 * result.first * result.first, 0.5 * result.second * result.second );
const auto b = std::max( 0.5 * result.first * result.first, 0.5 * result.second * result.second );
checksum += std::min(a, b);
```

|  | **GNU/8.1.0** | **Intel/18.0.3** |
|-|-|-|
| **14** | 82.8 | 80.0 |
| **15** | 33.4 | 32.4 |
(generated by `./bench_to_table.py bench.dat Markdown -C -f 'GNU/8|Intel/18' -t '14,15'`)

Just by using temporaries, the performances are increased by more than a factor 2 !!!

#### Tests 20 and 21

Test 20:
```C++
const auto a = result.second <= 0
            ? 0.5 * result.second * result.second
            : ( result.first >= 0 ? 0.5 * result.first * result.first : 0 );
const auto b = std::max(0.5 * result.first * result.first, 0.5 * result.second * result.second);
const real curr = result.first <= result.second ? a : b;
checksum += curr - last;
last = curr;
```

Test 21:
```C++
const auto a = result.second <= 0
            ? 0.5 * result.second * result.second
            : ( result.first >= 0 ? 0.5 * result.first * result.first : 0 );
const auto b = std::max(0.5 * result.first * result.first, 0.5 * result.second * result.second);
rec[i+1] = result.first <= result.second ? a : b;

...

// After applying the kernel on all discretization points.
for ( std::size_t i = 0; i < size; ++i )
    checksum += rec[i+1] - rec[i];
```

|  | **GNU/8.1.0** | **Intel/18.0.3** |
|-|-|-|
| **20** | 82.2 | 78.6 |
| **21** | 36.7 | 34.8 |
(generated by `./bench_to_table.py bench.dat Markdown -C -f 'GNU/8|Intel/18' -t '20,21'`)

Delaying the difference calculation by storing the reconstruction in
a temporary vector increases the performance by more than a factor 2
(even if it implies using more memory) !!!


## Differences with the C++-NoCopy version

The differences between this version and the `C++-NoCopy` version are:
- storing results of each branch of the ternary operator in `GodunovFlux.hpp`
- storing Weno reconstructions in a temporary vector before calculating the
  finite differences in `Weno.hpp` (this version is strictly not a "NoCopy"
  version)

The preprocessor constant `USE_ORIGINAL_VERSION` can be set in order to disable
this modifications.

Using 1000 discretization points, this version runs the general Weno benchmark
in 0.0945s (using GNU 8.1.0 on an Intel Xeon E5-2650 v4 @ 2.20GHz) compared
with 0.147s for the `C++-NoCopy` version, and 0.100s for the `Fortran` version.

Using 10000 discretization points, this version runs in 6.45s, the `C++-NoCopy`
version runs in 10.97s and the `Fortran` version runs in 7.30s.


# General instructions

### Choose your problem and your numerical flux

You must comment/uncomment the following lines in main.cpp
```
auto const problem = Burghers<Real>{};
//auto const problem = Convection<Real>{};
```
and
```
auto const num_flux = makeGodunovFlux(problem);
//auto const num_flux = makeLaxFriedrichsFlux(problem, 1.);
```

### Plotting:

In main.cpp, uncomment the line
```
#define DO_GNUPLOT_FILES
```
then, at run time, the code will produce a file _resultXXX_ every 100 steps, and
a file _gpfile_. To plot the solution over time, you can use gnuplot:
```
>gnuplot
load "gpfile"
```
But **CAVEAT**: **comment** the line for benchmarking!


### Compilation:
```
mkdir Build
cd Build
cmake ..
make
```
a file "run" is created.
To use an other compiler (eg. clang++) do:
```
CXX=clang++ cmake ..
make
```

### Run the code:

from Build/ directory, type:
```
./run
```
